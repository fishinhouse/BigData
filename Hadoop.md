Hadoop
===================

![github logo](http://2f.zol-img.com.cn/product/107/983/ce8r8kgzfTaoo.jpg)

Hadoop 带来了廉价的处理大数据（大数据的数据容量通常是10-100GB或更多，同时数据种类多种多样，包括结构化、非结构化等）的能力。

现今企业数据仓库和关系型数据库擅长处理结构化数据，并且可以存储大量的数据。但成本上有些昂贵。这种对数据的要求限制了可处理的数据种类，同时这种惯性所带的缺点还影响到数据仓库在面对海量异构数据时对于敏捷的探索。这通常意味着有价值的数据源在组织内从未被挖掘。这就是 Hadoop 与传统数据处理方式最大的不同。

MapReduce——Hadoop 的核心
---------------------------------

MapReduce 的重要创新是当处理一个大数据集查询时会将其任务分解并在运行的多个节点中处理。**当数据量很大时就无法在一台服务器上解决问题，此时分布式计算优势就体现出来。**将这种技术与 Linux 服务器结合可获得性价比极高的替代大规模计算阵列的方法。
    
而对于分布式计算，每个服务器必须具备对数据的访问能力，这就是 HDFS（Hadoop Distributed File System）所起到的作用。

HDFS 与 MapReduce 的结合是强大的。在处理大数据的过程中，当 Hadoop集群中的服务器出现错误时，整个计算过程并不会终止。同时 HFDS 可保障在整个集群中发生故障错误时的数据冗余。当计算完成时将结果写入 HFDS 的一个节点之中。HDFS 对存储的数据格式并无苛刻的要求，数据可以是非结构化或其它类别。相反关系数据库在存储数据之前需要将数据结构化并定义架构。

开发人员编写代码责任是使数据有意义。Hadoop MapReduce 级的编程利用 Java APIs，并可手动加载数据文件到 HDFS 之中。
　　
对于开发人员，直接使用 Java APIs 可能是乏味或容易出错的，同时也限制了 Java 程序员在 Hadoop 上编程的运用灵活性。于是 Hadoop 提供了两个解决方案，使得 Hadoop 编程变得更加容易。

- Pig (雅虎提供) 是一种编程语言，它简化了 Hadoop 常见的工作任务。Pig 可加载数据、表达转换数据以及存储最终结果。Pig 内置的操作使得半结构化数据变得有意义（如日志文件）。同时 Pig 可扩展使用 Java 中添加的自定义数据类型并支持数据转换。

- Hive (Facebook提供) 在 Hadoop 中扮演数据仓库的角色。Hive 添加数据的结构在 HDFS（hive superimposes structure on data in HDFS），并允许使用类似于 SQL 语法进行数据查询。与 Pig 一样，Hive 的核心功能是可扩展的。

Pig 和 Hive 总是令人困惑的。**Hive 更适合于数据仓库的任务，Hive 主要用于静态的结构以及需要经常分析的工作。**Hive 与 SQL 相似促使其成为 Hadoop 与其他 BI 工具结合的理想交集。Pig赋予开发人员在大数据集领域更多的灵活性，并允许开发简洁的脚本用于转换数据流以便嵌入到较大的应用程序。Pig 相比 Hive 相对轻量，它主要的优势是相比于直接使用 Hadoop Java APIs 可大幅削减代码量。正因为如此，Pig 仍然是吸引大量的软件开发人员。

HCatalog则基于Apache Hadoop之上的数据表和存储管理服务。
　　
改善数据访问：HBase、Sqoop 以及 Flume
-------------------------------------------

Hadoop 核心还是一套批处理系统，数据加载进HDFS、处理然后检索。对于计算这或多或少有些倒退，但通常互动和随机存取数据是有必要的。HBase 作为面向列的数据库运行在 HDFS 之上。HBase 以 Google BigTable为蓝本。项目的目标就是快速在主机内数十亿行数据中定位所需的数据并访问它。HBase 利用 MapReduce 来处理内部的海量数据。同时 Hive 和 Pig 都可以与 HBase 组合使用，Hive 和 Pig 还为 HBase 提供了高层语言支持，使得在 HBase 上进行数据统计处理变的非常简单。

但为了授权随机存储数据，HBase 也做出了一些限制：例如 Hive 与 HBase 的性能比原生在 HDFS 之上的 Hive 要慢4-5倍。同时 HBase 大约可存储 PB 级的数据，与之相比 HDFS 的容量限制达到 30PB。HBase 不适合用于 ad-hoc 分析，HBase 更适合整合大数据作为大型应用的一部分，包括日志、计算以及时间序列数据。
　　
获取数据与输出数据
-------------------------------------------
　　
Sqoop 和 Flume 可改进数据的互操作性和其余部分。
-Sqoop 功能主要是从关系数据库导入数据到 Hadoop，并可直接导入到 HFDS 或 Hive。
-Flume 设计旨在直接将流数据或日志数据导入 HDFS。

Hive 具备的友好 SQL 查询是与繁多数据库的理想结合点，数据库工具通过 JDBC 或 ODBC 数据库驱动程序连接。
　　
负责协调工作流程的 ZooKeeper 和 Oozie
----------------------------------------------
　　
随着越来越多的项目加入 Hadoop 大家庭并成为集群系统运作的一部分，大数据处理系统需要负责协调工作的的成员。**随着计算节点的增多，集群成员需要彼此同步并了解去哪里访问服务和如何配置，ZooKeeper 正是为此而生的。**

**而在 Hadoop 执行的任务有时候需要将多个 Map/Reduce 作业连接到一起，它们之间或许批次依赖。Oozie 组件提供管理工作流程和依赖的功能，并无需开发人员编写定制的解决方案。**

Ambari 是最新加入 Hadoop 的项目，**Ambari 项目旨在将监控和管理等核心功能加入 Hadoop 项目。**Ambari 可帮助系统管理员部署和配置 Hadoop，升级集群以及监控服务。还可通过 API 集成与其他的系统管理工具。

Apache Whirr 是一套运行于云服务的类库（包括 Hadoop），可提供高度的互补性。Whirr 现今相对中立，当前支持 Amazon EC2 和 Rackspace 服务。
　　
机器学习：Mahout
------------------------------------------
　　
各类组织需求的不同导致相关的数据形形色色，对这些数据的分析也需要多样化的方法。Mahout 提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。**Mahout 包含许多实现，包括集群、分类、推荐过滤、频繁子项挖掘。**


Hadoop：先加载，再组织！
==============================
Database：先组织，再加载！
==============================


英特尔Hadoop发行版管理工具（一站式安装、部署、配置、监控和告警）
------------------------------------------------------------------
![github logo](http://2c.zol-img.com.cn/product/107/752/ceY86JQDAeks.jpg)



